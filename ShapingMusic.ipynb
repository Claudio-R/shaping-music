{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xlTv6JKLfJ6"
      },
      "source": [
        "# Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYF8JjaBLaUo"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "from IPython import display\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UTILS\n",
        "def load_img(path_to_img):\n",
        "    max_dim = 512\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    long_dim = max(shape)\n",
        "    scale = max_dim / long_dim\n",
        "\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "\n",
        "def imshow(image, title=None):\n",
        "    if len(image.shape) > 3:\n",
        "        image = tf.squeeze(image, axis=0)\n",
        "        plt.imshow(image)\n",
        "    if title:\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "absolute_path_yamnet = '/home/claudio-unix/mae/ShapingMusic/yamnet_pkg'\n",
        "sys.path.insert(1, absolute_path_yamnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMAGE_MODEL\n",
        "image_model = tf.keras.applications.VGG19(\n",
        "    include_top=True,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# AUDIO MODEL\n",
        "from yamnet_pkg import inference\n",
        "sound_model = inference.YamNet()\n",
        "\n",
        "# TEXT-TO-IMAGE GENERATOR\n",
        "import yaml\n",
        "import openai\n",
        "with open(\"apikey.local.yml\", \"r\") as stream:\n",
        "    try:\n",
        "        openai.api_key = yaml.safe_load(stream)['apikey']\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "        print('Cannot load the APIKey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Audio_Image_Classifier:\n",
        "    '''\n",
        "    Class responsible for multimodal classification.\n",
        "    Given an audio track and the corresponding sequence of frames to classify, produces a string by concatenating labels.\n",
        "    sound_model: pretrained tf.Model for audio classification\n",
        "    image_model: pretrained tf.Model for image classification\n",
        "    '''\n",
        "\n",
        "    def __init__(self, image_model, sound_model):\n",
        "        # IMAGE_MODEL\n",
        "        self.image_model = image_model\n",
        "        # SOUND_MODEL\n",
        "        self.sound_model = sound_model\n",
        "    \n",
        "    def __call__(self, img, snd):\n",
        "        input_img = tf.keras.applications.vgg19.preprocess_input(img * 255)\n",
        "        input_img = tf.image.resize(input_img, (224, 224))\n",
        "        predictions_img = self.image_model(input_img)\n",
        "        predictions_img = tf.keras.applications.vgg19.decode_predictions(predictions_img.numpy())[0]\n",
        "        predictions_snd = sound_model(snd)\n",
        "        text = self.__parse_predictions(predictions_img, predictions_snd)\n",
        "        print('Input Labels: ', text)\n",
        "        self.__generate_image(text)\n",
        "\n",
        "    def __generate_image(self, text):\n",
        "        response = openai.Image.create(\n",
        "            prompt = text,\n",
        "            n=1,\n",
        "            size=\"512x512\"\n",
        "        )\n",
        "        image_url = response['data'][0]['url']\n",
        "        response = requests.get(image_url)\n",
        "        img = PIL.Image.open(BytesIO(response.content))\n",
        "        img.show()\n",
        "    \n",
        "    def __parse_predictions(self, predictions_img, predictions_snd):\n",
        "        predictions_img = [class_name for (number, class_name, prob) in predictions_img]\n",
        "        predictions_img = [class_name.split('_') for class_name in predictions_img]\n",
        "        input_text = predictions_snd\n",
        "        for words in predictions_img:\n",
        "            for w in words:\n",
        "                input_text.append(w)\n",
        "        return ' '.join(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = Audio_Image_Classifier(image_model, sound_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_snd = 'data/car.wav'\n",
        "test_img = load_img('data/labrador.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier(test_img, test_snd)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd47853e32cf332c7e23a177cc7406abfb96bfc3fe21f7dd172e4dde369451e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
